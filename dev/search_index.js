var documenterSearchIndex = {"docs":
[{"location":"schema/#Schema","page":"Schema","title":"Schema","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"The goal of the schema is to discover the structure of JSON files. By structure we inderstand the specification of types of internal nodes (Dict, Array, Values). Besides, the schema holds statistics about how many times the node has been presented and also frequency of appereances of values in leafs. The latter is a useful information for deciding, how to represent (convert) valus in leafs to tensor. The schema might be usefol for formats with enforced schema to collect statistics on leafs.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"JsonGrinder.schema collect statistics from a set of JSONs. Statistics are collected in a hierarchical structure reflecting the structured composed of DictEntry, ArrayEntry, and Entry. These structures reflects the those in JSON: Dict, Array, and Value (either String or a Number). Sometimes, data are stored in JSONs not adhering to a stable schema, which happens if one key have childs of different type. An example of such would be ","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"{\"a\" = [1,2,3]}\n{\"a\" = {b = 1}}\n{\"a\" = \"hello\"}","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"For these cases, we have introduced additional Entry, a MultiEntry, but we discourage to rely on this feature and recommend to adapts JSONs to have stable schema (if possible).","category":"page"},{"location":"schema/#Entry","page":"Schema","title":"Entry","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"mutable struct Entry{T} <: JSONEntry\n\tcounts::Dict{T,Int}\n\tupdated::Int\nend","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"Entry keeps information about leaf-values (e.g. \"a\" = 3) (strings or numbers) in JSONs. It consists of two statistics","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"updated counts how many times the leaf with a given key was observed,\ncounts counts how many times a particular value of the leaf was observed.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"To keep counts from becoming too large, once its length exceeds updatemaxkeys (default 10 000), then the new values will be dropped. This value can be changed by updatemaxkeys!, but of course the new limit will be applied to newly processed values.","category":"page"},{"location":"schema/#ArrayEntry","page":"Schema","title":"ArrayEntry","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"mutable struct ArrayEntry <: JSONEntry\n\titems\n\tl::Dict{Int,Int}\n\tupdated::Int\nend","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"ArrayEntry keeps information about arrays (e.g. \"a\" = [1,2,3,4]). Statistics about individual items of the array are deffered to item, which can be <:JSONEntry. l stores keeps histogram of lengts of arrays, and updated is keep number of times this key has been observed.","category":"page"},{"location":"schema/#DictEntry","page":"Schema","title":"DictEntry","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"mutable struct DictEntry <: JSONEntry\n\tchilds::Dict{Symbol, Any}\n\tupdated::Int\nend","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"deferes all statistics about its children to them, and the only statistic is again a counter updated, about observation times.","category":"page"},{"location":"schema/#MultiEntry","page":"Schema","title":"MultiEntry","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"mutable struct MultiEntry <: JSONEntry\n\tchilds::Vector{JSONEntry}\n\tupdated::Int\nend","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"is a failsave for cases, where the schema is not stable. For example in following two JSONs","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"{\"a\" = \"Hello\"}\n{\"a\" = [\"Hello\",\" world\"]}","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"the type of a value of a key \"a\" is String, whereas in the second it is \"Vector\". The JsonGrinder will deal with this by first creating an Entry, since the value is scalar, and upon encountering the second JSON, it will replace Entry with MultiEntry having Entry and ArrayEntry as childs (this is the reason why entries are declared mutable). ","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"While JsonGrinder can deal with non-stable jsons, it is strongly discouraged as it might have negative effect on the performance.","category":"page"},{"location":"schema/#Extra-functions","page":"Schema","title":"Extra functions","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"While schema can be printed to REPL, it can contain quite a lot of information. Therefore JsonGrinder.generate_html exports it to HTML, where parts can be expanded at wish.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"JsonGrinder.generate_html","category":"page"},{"location":"schema/#JsonGrinder.generate_html","page":"Schema","title":"JsonGrinder.generate_html","text":"generate_html(sch::DictEntry; max_vals=100, max_len=1_000)\ngenerate_html(sch::DictEntry, file_name ; max_vals=100, max_len=1_000)\n\nexport schema to HTML including CSS style allowing to expand / hide\nsub-parts of schema, countmaps, and lengthmaps.\n\n`max_vals` controls maximum number of exported values in countmap\n`max_len` controls maximum number of exported lengts of arrays\n`file_name` a name of file to save HTML with schema\n\n\n\n\n\n","category":"function"},{"location":"schema/","page":"Schema","title":"Schema","text":"JsonGrinder.merge","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"Schema supports merging using Base.merge, which facilitates paralel computation of schemas. An example might be","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"ThreadsX.mapreduce(schema, merge, Iterators.partition(jsons, div(length(jsons), Threads.nthreads())))","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"JsonGrinder.prune_json","category":"page"},{"location":"schema/#JsonGrinder.prune_json","page":"Schema","title":"JsonGrinder.prune_json","text":"prune_json(json, schema)\n\nremove keys from json which are not part of the schema\n\n\n\n\n\n","category":"function"},{"location":"schema/","page":"Schema","title":"Schema","text":"JsonGrinder.updatemaxkeys!","category":"page"},{"location":"schema/#JsonGrinder.updatemaxkeys!","page":"Schema","title":"JsonGrinder.updatemaxkeys!","text":"updatemaxkeys!(n::Int)\n\nlimits the maximum number of keys in statistics of nodes in JSON. Default value is 10000.\n\n\n\n\n\n","category":"function"},{"location":"schema/","page":"Schema","title":"Schema","text":"JsonGrinder.updatemaxlen!","category":"page"},{"location":"schema/#JsonGrinder.updatemaxlen!","page":"Schema","title":"JsonGrinder.updatemaxlen!","text":"updatemaxlen!(n::Int)\n\nlimits the maximum size of string values in statistics of nodes in JSON. Default value is 10000.\nLonger strings will be trimmed and their length and hash will be appended to retain the uniqueness.\nThis is due to some strings being very long and causing the schema to be even order of magnitute larger than needed.\n\n\n\n\n\n","category":"function"},{"location":"exfunctions/#Extractor-functions","page":"Extractor functions","title":"Extractor functions","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Below, we first describe extractors of values (i.e. lists of JSON tree), then proceed to description of extractors of Array and Dict, and finish with some specials.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Extractors of scalar values are arguably the most important, but also fortunatelly the most undersood ones. They control, how values are converted to a Vector (or generally tensor) for the neural networks. For example they control, if number should be represented as a number, or as one-hot encoded categorical variable. Similarly, it constrols how String should be treated, although we admit to natively support on ngrams. Recall ","category":"page"},{"location":"exfunctions/#Numbers","page":"Extractor functions","title":"Numbers","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"struct ExtractScalar{T}\n\tc::T\n\ts::T\nend","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Extract a numerical value, centred by subtracting c and scaled by multiplying by s.  Strings are converted to numbers. The extractor returnes ArrayNode{Matrix{T}}  with a single row. ","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"using JsonGrinder, Mill, JSON #hide\ne = ExtractScalar(Float32, 0.5, 4.0)\ne(\"1\").data","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"missing value is extracted as a missing value, as it is automatically handled downstream by Mill.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"e(missing)","category":"page"},{"location":"exfunctions/#Strings","page":"Extractor functions","title":"Strings","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"struct ExtractString{T}\n\tdatatype::Type{T}\n\tn::Int\n\tb::Int\n\tm::Int\nend","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Represent String as n-grams (NGramMatrix from Mill.jl) with base b and modulo m.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"e = ExtractString()\ne(\"Hello\")","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"missing value is extracted as a missing value, as it is automatically handled downstream by Mill.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"e(missing)","category":"page"},{"location":"exfunctions/#Categorical","page":"Extractor functions","title":"Categorical","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"struct ExtractCategorical{V,I} <: AbstractExtractor\n\tkeyvalemap::Dict{V,I}\n\tn::Int\nend","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Converts a single item to a one-hot encoded vector. For a safety, there is always an  extra item reserved for an unknown value. ","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"e = ExtractCategorical([\"A\",\"B\",\"C\"])\ne([\"A\",\"B\",\"C\",\"D\"]).data","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"missing value is extracted as a missing value, as it is automatically handled downstream by Mill.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"e(missing)","category":"page"},{"location":"exfunctions/#Array-(Lists-/-Sets)","page":"Extractor functions","title":"Array (Lists / Sets)","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"struct ExtractArray{T}\n\titem::T\nend","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Convert array of values to a Mill.BagNode with items converted by item. The entire array is assumed to be a single bag.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"sc = ExtractArray(ExtractCategorical([\"A\",\"B\",\"C\"]))\nsc([\"A\",\"B\",\"C\",\"D\"])","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Empty arrays are represented as an empty bag.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"sc([]).bags","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"The data of empty bag can be either missing or a empty sample, which is more convenient as it makes all samples of the same type, which is nicer to AD. This behavior is controlled by Mill.emptyismissing. The extractor of a BagNode can signal to child extractors to extract a sample with zero observations using a special singleton JsonGrinder.extractempty. For example","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Mill.emptyismissing!(true)\nsc([]).data","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Mill.emptyismissing!(false)\nsc([]).data","category":"page"},{"location":"exfunctions/#Dict","page":"Extractor functions","title":"Dict","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"struct ExtractDict\n\tdict::Dict{Symbol,Any}\nend\n","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Extracts all items in dict and return them as a ProductNode. Key in dict corresponds to keys in JSON. ","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"ex = ExtractDict(Dict(:a => ExtractScalar(), \n\t:b => ExtractString(), \n\t:c => ExtractCategorical([\"A\",\"B\"]),\n\t:d => ExtractArray(ExtractString())))\nex(Dict(:a => \"1\",\n\t:b => \"Hello\",\n\t:c => \"A\",\n\t:d => [\"Hello\", \"world\"]))","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Missing keys are replaced by missing and handled by child extractors.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"ex(Dict(:a => \"1\",\n\t:c => \"A\"))","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Describe extractempty to signal that we need to extract empty variable","category":"page"},{"location":"exfunctions/#Specials","page":"Extractor functions","title":"Specials","text":"","category":"section"},{"location":"exfunctions/#ExtractKeyAsField","page":"Extractor functions","title":"ExtractKeyAsField","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Some JSONs we have encountered uses structure to hold an array for named lists (or other types). Having computer security background a prototypical example is storing a list of DLLs with a corresponding list of imported function in a single structure. For example a JSON","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"{ \"foo.dll\" : [\"print\",\"write\", \"open\",\"close\"],\n  \"bar.dll\" : [\"send\", \"recv\"]\n}","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"should be better written as ","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"[{\"key\" = \"foo.dll\",\n  \"item\" = [\"print\",\"write\", \"open\",\"close\"]},\n  {\"key = \"bar.dll\",\n  \"item\" = [\"send\", \"recv\"]}\n]","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"JsonGrinder tries to detect these cases, as they are typically manisfested by Dicts with excessively large number of keys in a schema. The detection logic of this case in suggestextractor(e::DictEntry) is simple, if the number of keys is greater than settings.key_as_field = 500.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"The extractor itself is simple as well. For the case above, it would look like ","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"s = JSON.parse(\"{ \\\"foo.dll\\\" : [\\\"print\\\",\\\"write\\\", \\\"open\\\",\\\"close\\\"],\n  \\\"bar.dll\\\" : [\\\"send\\\", \\\"recv\\\"]\n}\")\nex = ExtractKeyAsField(ExtractString(),ExtractArray(ExtractString()))\nex(s)","category":"page"},{"location":"exfunctions/#MultipleRepresentation","page":"Extractor functions","title":"MultipleRepresentation","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Provides a dual representation for a single key. For example imagine that are extracting strings with some very freuquently occuring values and a lots of clutter, which might be important and you do not know about it. MultipleRepresentation(extractors::Tuple) contains a Tuple or NamedTuple of extractors and apply them to a single sub-tree in a json. The corresponding Mill structure will contain ProductNode of both representation.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"For example String with Categorical and NGram representation will look like.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"ex = MultipleRepresentation((c = ExtractCategorical([\"Hello\",\"world\"]), s = ExtractString()))\nreduce(catobs,ex.([\"Hello\",\"world\",\"from\",\"Prague\"]))","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"MultipleRepresentation together with handling of missing values enables JsonGrinder to deal with JSONs with non-stable schema.","category":"page"},{"location":"exfunctions/#ExtractOneHot(ks,-k,-v)","page":"Extractor functions","title":"ExtractOneHot(ks, k, v)","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Some JSONs we have encountered encode histograms in a an array containing structures with a name of the bin and its count. In the example below, the name of the bin (further called key) and corresponding count in the bin is called value. In example below, key is equal to name and the value is equal to count.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"[{\\\"name\\\": \\\"a\\\", \\\"count\\\" : 1},\n{\\\"name\\\": \\\"b\\\", \\\"count\\\" : 2}]","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"This histogram is extracted as a BagNode with a wrapped SparseMatrix containing the key-value pairs, each pair in a separate We represent them as SparseMatrices with one line per item for example as","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"vs = JSON.parse(\"[{\\\"name\\\": \\\"a\\\", \\\"count\\\" : 1}, {\\\"name\\\": \\\"b\\\", \\\"count\\\" : 2}]\")\ne = ExtractOneHot([\"a\",\"b\"], \"name\", \"count\");\ne(vs).data","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Notice that the matrix has an extra dimension  reserved for unknown keys. The array is handled as a bag. For example for the above example","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"e(vs)","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"The extractor itself is a structure defined as","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"struct ExtractOneHot{K,I,V} <: AbstractExtractor\n\tk::K\n\tv::V\n\tkey2id::Dict{I,Int}\n\tn::Int\nend","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"where k / v is the name of an entry indetifying key / value, and key2id converts the value of the key to the the index in the sparse array. A constructor ExtractOneHot(ks, k, v) assumes k and v as above and ks being list of key values. ","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"#explain, how to customize conversion of schema to extractors extractors to ","category":"page"},{"location":"extractors/#Creating-extractor","page":"Creating extractors","title":"Creating extractor","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Extractor is responsible for converting json to Mill structures. The main design idea is that the extractor for a whole json is created by composing (sub-)extractors while reflecting the JSON structure. This composability is achieved by the commitment of each extractor returning a subtype of Mill.AbstractDataNode. Extractor can be any function, but to ensure a composability, it is should be a subtype of AbstractExtractor, which means all of them being implemented as functors (also because they contain parameters). ","category":"page"},{"location":"extractors/#Manual-creation-of-extractors","page":"Creating extractors","title":"Manual creation of extractors","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"The simples way to create a custom extractor is the compose it from provided extractor functions. Imagine for example json file as follows.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"{\"name\" = \"Karl\",\n \"siblings\" = [\"Gertruda\", \"Heike\", \"Fritz\"],\n \"hobby\" = [\"running\", \"pingpong\"],\n \"age\" = 21,\n}","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"A corresponding extractor might look like","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"using JsonGrinder, Mill, JSON #hide\nex = ExtractDict(Dict(\n\t:name => ExtractString(),\n\t:siblings => ExtractArray(ExtractString()),\n\t:hobby => ExtractArray(ExtractCategorical([\"running\", \"swimming\",\"yoga\"])),\n\t:age => ExtractScalar(),\n\t))","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Notice, how the composability of extractors simplifies the desing and allow to reflect the same feature of JSON documents.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Applying the extractor ex on the above json yield the corresponding Mill structure.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"s = JSON.parse(\"{\\\"name\\\" : \\\"Karl\\\",\n \\\"siblings\\\" : [\\\"Gertruda\\\", \\\"Heike\\\", \\\"Fritz\\\"],\n \\\"hobby\\\" : [\\\"running\\\", \\\"pingpong\\\"],\n \\\"age\\\" : 21\n}\")\nex(s)","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"The list of composable extractor function that we have found handy during our experiments are listed in Extractor functions section of the doc.","category":"page"},{"location":"extractors/#Semi-automatic-creation-of-extractors","page":"Creating extractors","title":"Semi-automatic creation of extractors","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Manually creating extractors is boring and error-prone process. Function suggestextractor(schema) tries to simplify this, since creation of most of the extractors is straightforward, once the the schema is known. This is especially true for Dict and Arrays, while extractors for leafs can be tricky, as one needs to decide, if the leaf should be represented as a  Float and String are represented as Categorical variables. suggestextractor(schema) uses a simple heuristic (described below) choosing reasonable extractors, but it can make errors. It is therefore highly recommended to check the proposed extractor manually, if it makes sense. A typical error, especially if schema is created from a small number of samples, is that some variable is treated as a categorical, while it should be String / Float.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"JsonGrinder.suggestextractor(schema, settings::NamedTuple)\n","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"allows to pass your own heuristic and rules for handling scalars. By default, settings = (scalar_extractors = default_scalar_extractor()). Extractors for Dict and Arrays are not configurable, as we do not feel the pressure to so, as there does not seems to be much to do, but of course there is some dark magic described below.","category":"page"},{"location":"extractors/#Scalars","page":"Creating extractors","title":"Scalars","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"scalar_extractors is a list of tuples, where the first is a condition and the second is a function creating the extractor in case of a true. The default heuristic is following and  you can adjust according to your liking. ","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"function default_scalar_extractor()\n\t[\n\t# all floatable keys are also intable AFAIK\n\t(e -> length(keys(e)) <= 100 && is_floatable(e),\n\t\te -> ExtractCategorical(keys(e))),\n\t# it's important that condition here would be lower than maxkeys\n\t(e -> (keys_len = length(keys(e)); keys_len / e.updated < 0.1 && keys_len < 10000),\n\t\te -> ExtractCategorical(keys(e))),\n\t(e -> is_intable(e),\n\t\te -> extractscalar(Int32, e)),\n\t(e -> is_floatable(e),\n\t \te -> extractscalar(FloatType, e)),\n\t(e -> true,\n\t\te -> extractscalar(unify_types(e), e)),]\nend","category":"page"},{"location":"extractors/#Arrays","page":"Creating extractors","title":"Arrays","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Extractor suggested for ArrayEntry is most of the time ExtractArray converting Arrays to Mill.BagNodes. The exception is the case, when vectors are of the same length and their items are numbers. In this case, the suggestextractor returns ExtractVector, which treats convert the array to a Mill.ArrayNode, as we believe the array to represent a feature vector.","category":"page"},{"location":"extractors/#Dict","page":"Creating extractors","title":"Dict","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Extractor suggested for DictEntry is most of the time ExtractDict converting Dicts to ProductNodes. Again, there is an excetion. Sometimes, people use Dicts with names of keys being values. For example consider following two jsons","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"{\"a.dll\" = [\"f\", \"g\", \"h\"],\n \"b.dll\" = [\"a\", \"b\", \"c\"]}\n{\"c.dll\" = [\"x\", \"y\", \"z\"]}","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"in the case, keys [\"a.dll\",\"b.dll\",\"c.dll\"] are actually values (names of libraries), and arrays are values as well. The dictionary therefore contain an array. If this case is detected, it is suggested to use ExtractKeyAsField, which interprests the above JSON as ","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"[{key = \"a.dll\", \n  field = [\"f\", \"g\", \"h\"]},\n {key = \"b.dll\",\n field = [\"a\", \"b\", \"c\"]}\n]\n[{key = \"c.dll\",\nfield = [\"x\", \"y\", \"z\"]}]","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"ExtractKeyAsField extractor convert it to Mill.BagNode(Mill.ProductNode((key=..., field=...)))","category":"page"},{"location":"developers/#Implementing-new-Extractor","page":"Developers","title":"Implementing new Extractor","text":"","category":"section"},{"location":"developers/","page":"Developers","title":"Developers","text":"Mill.emptyismissing","category":"page"},{"location":"#JsonGrinder.jl","page":"Home","title":"JsonGrinder.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"JsonGrinder.jl is a companion to Mill.jl aimed to ease your pain when performing learning on real world data stored in JSON format. As you know, most machine learning libraries assume that your data are stored as tensors of a fixed dimension, or a sequence. Contrary, JsonGrider.jl assumes your data are stored in JSON format, which is flexible, and it is sufficient to convert only leaf values to a tensor, which is typically trivial. The rest is magically sorted out. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"JsonGrinder tries to provide reasonable defaults, but if you want, you can customize and tweak almost anything according to your imagination and desire. Last but not least, although JsonGrinder was designed for JSON files, you can easily adapt it to XML, ProtoBuffers, MessagePacks,...","category":"page"},{"location":"","page":"Home","title":"Home","text":"There are four steps to create a classifier once you load the data.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Create a schema of JSON files (using sch = JsonGrinder.schema).\nCreate an extractor converting JSONs to Mill structures (extractor = suggestextractor(sch))). Schema sch  from previous step is very helpful, as it helps to identify, how to convert nodes (Dict, Array) to (Mill.ProductNode and Mill.BagNode) and how to convert values in leafs to (Float32, Vector{Float32}, String, Categorical).\nCreate a model for your JSONs, which can be easily done by (using model = reflectinmodel(sch, extractor,...))\nUse your favourite methods to train the model, it is 100% compatible with Flux.jl tooling.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Authors see the biggest advantage in the model being hierarchical and reflecting the JSON structure. Thanks to Mill.jl, it can handle missing values at all levels. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Our idealized workflow is demonstrated in examples/identification.jl solving device identification challenge looks as follows (for many datasets which fits in memory it suggest just to change the key with labels (:device_class) and names of files):","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Flux, MLDataPattern, Mill, JsonGrinder, JSON, Statistics, IterTools\nusing StatsBase\nusing Serialization\nusing JsonGrinder: suggestextractor, ExtractDict\nusing Mill: reflectinmodel\n\n#####\n# start by loading all samples\n#####\nsamples = map(readlines(\"train.json\")) do s\n\tJSON.parse(s)\nend;\nJSON.print(samples[3],2)\n\n\n#####\n# create schema of the JSON\n#####\nsch = JsonGrinder.schema(samples);\nextractor = suggestextractor(sch)\nextract_target = ExtractDict(nothing, Dict(:device_class => extractor.other[:device_class]));\n\ntarget = extractbatch(extract_target, samples).data\ndelete!(extractor.other, :device_class);\ndata = extractbatch(extractor, samples)\n\nds = extractor(JsonGrinder.sample_synthetic(sch))\nmodel = reflectinmodel(ds, d -> Dense(d,20, relu), d -> SegmentedMeanMax(d), b = Dict(\"\" => d -> Chain(Dense(d, 20, relu), Dense(20, size(target,1)))));\nmodel(ds)\n\n#####\n#  train\n#####\nfunction makebatch()\n\ti = rand(1:nobs(data), 100)\n\tdata[i], target[:,i]\nend\nopt = ADAM()\nps = params(model)\nloss = (x,y) -> Flux.logitcrossentropy(model(x).data,y)\n\ncb = () -> begin\n\to = model(data).data\n\tprintln(\"crossentropy = \",Flux.logitcrossentropy(o,target) ,\" accuracy = \",mean(Flux.onecold(softmax(o)) .== Flux.onecold(target)))\nend\nFlux.Optimise.train!(loss, ps, repeatedly(makebatch,10000), opt, cb = Flux.throttle(cb, 60))\n\n\n#####\n#  Classify test data\n#####\ntest_samples = map(readlines(\"test.json\")) do s\n\textractor(JSON.parse(s))\nend\no = Flux.onecold(model(reduce(catobs, test_samples)).data);\nns = extract_target[:device_class].keyvalemap\nns = Dict([ v => k for (k,v) in ns]...)\no = [ns[i] for i in o]\n","category":"page"},{"location":"#A-walkthrough-of-the-example","page":"Home","title":"A walkthrough of the example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Include libraries and load the data.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Flux, MLDataPattern, Mill, JsonGrinder, JSON, IterTools, Statistics, BenchmarkTools, ThreadTools\nusing JsonGrinder: suggestextractor\nusing Mill: reflectinmodel\n\nsamples = map(readlines(\"train.json\")) do s\n\tJSON.parse(s)\nend;","category":"page"},{"location":"","page":"Home","title":"Home","text":"labelkey = \"device_class\"\nminibatchsize = 100\niterations = 10_000\nneurons = 20 \t\t# neurons per layer","category":"page"},{"location":"","page":"Home","title":"Home","text":"Create labels and remove them from data, such that we do not use them as features. We also remove id key, such that we do not predict it","category":"page"},{"location":"","page":"Home","title":"Home","text":"targets = map(i -> i[labelkey], samples)\nforeach(i -> delete!(i, labelkey), samples)\nforeach(i -> delete!(i, \"id\"), samples)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Create the schema of data","category":"page"},{"location":"","page":"Home","title":"Home","text":"sch = JsonGrinder.schema(samples)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Create the extractor converting jsons to Mill structure. The suggestextractor is executed below with default setting, but it allows you heavy customizing.","category":"page"},{"location":"","page":"Home","title":"Home","text":"extractor = suggestextractor(sch)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Convert jsons to mill data samples.","category":"page"},{"location":"","page":"Home","title":"Home","text":"data = tmap(extractor, samples)\nlabelnames = unique(targets)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Create the model according to the data","category":"page"},{"location":"","page":"Home","title":"Home","text":"model = reflectinmodel(sch, extractor,\n\tk -> Dense(k, neurons, relu),\n\td -> SegmentedMeanMax(d),\n\tb = Dict(\"\" => k -> Dense(k, length(labelnames))),\n)","category":"page"},{"location":"","page":"Home","title":"Home","text":"After definiting few usual function, we start training.","category":"page"},{"location":"","page":"Home","title":"Home","text":"function minibatch()\n\tidx = sample(1:length(data), minibatchsize, replace = false)\n\treduce(catobs, data[idx]), Flux.onehotbatch(targets[idx], labelnames)\nend\n\naccuracy(x,y) = mean(map(xy -> labelnames[argmax(model(xy[1]).data[:])] == xy[2], zip(x, y)))\n\ncb = () -> println(\"accuracy = \", accuracy(valdata...))\nps = Flux.params(model)\nloss = (x,y) -> Flux.logitcrossentropy(model(x).data, y)\nFlux.Optimise.train!(loss, ps, repeatedly(minibatch, iterations), ADAM(), cb = Flux.throttle(cb, 2))","category":"page"}]
}
